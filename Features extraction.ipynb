{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "def read_csv(filename, hasHeader=False):\n",
    "    data = []\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        if (hasHeader):\n",
    "            next(reader, None)\n",
    "            \n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train items 3344613\n",
      "Item example ['1', '81', '\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0\\xd0\\xbc \\xd0\\x9a\\xd0\\xb0\\xd0\\xbc\\xd0\\xb0\\xd0\\xb7 6520', '\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0\\xd0\\xbc \\xd0\\x9a\\xd0\\xb0\\xd0\\xbc\\xd0\\xb0\\xd0\\xb7 6520 20 \\xd1\\x82\\xd0\\xbe\\xd0\\xbd\\xd0\\xbd', '1064094, 5252822, 6645873, 6960145, 9230265', '{\"\\xd0\\x92\\xd0\\xb8\\xd0\\xb4 \\xd1\\x82\\xd0\\xb5\\xd1\\x85\\xd0\\xbd\\xd0\\xb8\\xd0\\xba\\xd0\\xb8\":\"\\xd0\\x93\\xd1\\x80\\xd1\\x83\\xd0\\xb7\\xd0\\xbe\\xd0\\xb2\\xd0\\xb8\\xd0\\xba\\xd0\\xb8\"}', '300000.0', '648140', '', '64.686946', '30.815924']\n"
     ]
    }
   ],
   "source": [
    "items = read_csv('data/ItemInfo_train.csv', hasHeader=True)\n",
    "print 'Train items', len(items)\n",
    "print 'Item example', items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COL_ITEM_ID=0\n",
    "COL_CATEGORY_ID=1\n",
    "COL_TITLE=2\n",
    "COL_DESCRIPTION=3\n",
    "COL_IMAGES=4\n",
    "COL_JSON=5\n",
    "COL_PRICE=6\n",
    "COL_LOCATION=7\n",
    "COL_METRO=8\n",
    "COL_LAT=9\n",
    "COL_LON=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_items = dict()\n",
    "for item in items:\n",
    "    map_items[item[COL_ITEM_ID]] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs 99713\n",
      "Example pair ['1', '4112648', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "pairs = read_csv('data/ItemPairs_train.csv', hasHeader=True)\n",
    "pairs = pairs[:len(pairs)/30]\n",
    "print 'Train pairs', len(pairs)\n",
    "print 'Example pair', pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories 52\n"
     ]
    }
   ],
   "source": [
    "categories = read_csv('data/Category.csv')\n",
    "print 'Categories', len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_parent_category = dict()\n",
    "for category in categories:\n",
    "    map_parent_category[category[0]] = category[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations 3449\n"
     ]
    }
   ],
   "source": [
    "locations = read_csv('data/Location.csv', hasHeader=True)\n",
    "print 'Locations', len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_regions = dict()\n",
    "for location in locations:\n",
    "    map_regions[location[0]] = location[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_images(item1, item2):\n",
    "    imgs1 = item1[COL_IMAGES].split(',')\n",
    "    imgs2 = item2[COL_IMAGES].split(',')\n",
    "    imgs1 = [x.strip() for x in imgs1]\n",
    "    imgs2 = [x.strip() for x in imgs2]\n",
    "    \n",
    "    return set(imgs1) == set(imgs2)\n",
    "\n",
    "def number_of_same_images(item1, item2):\n",
    "    imgs1 = item1[COL_IMAGES].split(',')\n",
    "    imgs2 = item2[COL_IMAGES].split(',')\n",
    "    imgs1 = set([x.strip() for x in imgs1])\n",
    "    imgs2 = set([x.strip() for x in imgs2])\n",
    "    \n",
    "    minlen = min(len(imgs1), len(imgs2))\n",
    "    \n",
    "    if minlen == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(imgs1.intersection(imgs2)) / minlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize)\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    try:\n",
    "        tfidf = vectorizer.fit_transform([text1, text2])\n",
    "        return ((tfidf * tfidf.T).A)[0,1]\n",
    "    except:\n",
    "        return 1.0 if text1 == text2 else 0.0\n",
    "\n",
    "def same_title(item1, item2):\n",
    "    return cosine_sim(item1[COL_TITLE], item2[COL_TITLE])\n",
    "\n",
    "def same_description(item1, item2):\n",
    "    return cosine_sim(item1[COL_DESCRIPTION], item2[COL_DESCRIPTION])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_category(item1, item2):\n",
    "    cat1 = item1[COL_CATEGORY_ID]\n",
    "    cat2 = item2[COL_CATEGORY_ID]\n",
    "    \n",
    "    return 1 if cat1 == cat2 else 0\n",
    "\n",
    "def same_parent_category(item1, item2):\n",
    "    cat1 = item1[COL_CATEGORY_ID]\n",
    "    cat2 = item2[COL_CATEGORY_ID]\n",
    "    \n",
    "    par_cat1 = map_parent_category[cat1]\n",
    "    par_cat2 = map_parent_category[cat2]\n",
    "    \n",
    "    return 1 if par_cat1 == par_cat2 else 0\n",
    "\n",
    "def same_price(item1, item2):\n",
    "    price1 = item1[COL_PRICE]\n",
    "    price2 = item2[COL_PRICE]\n",
    "    \n",
    "    return 1 if price1 == price2 else 0\n",
    "\n",
    "def safe_parse(str):\n",
    "    try:\n",
    "        return float(item1[COL_PRICE].replace(',', ''))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def price_diff_percent(item1, item2):\n",
    "    price1 = safe_parse(item1[COL_PRICE])\n",
    "    price2 = safe_parse(item2[COL_PRICE])\n",
    "    \n",
    "    import math\n",
    "    avg_price = (price1 + price2) / 2.0\n",
    "    \n",
    "    if avg_price != 0:\n",
    "        return math.fabs(price1 - price2) / avg_price\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_lat(item1, item2):\n",
    "    lat1 = item1[COL_LAT]\n",
    "    lat2 = item2[COL_LAT]\n",
    "    \n",
    "    return 1 if lat1 == lat2 else 0\n",
    "\n",
    "def same_lon(item1, item2):\n",
    "    lon1 = item1[COL_LON]\n",
    "    lon2 = item2[COL_LON]\n",
    "    \n",
    "    return 1 if lon1 == lon2 else 0\n",
    "\n",
    "def same_location(item1, item2):\n",
    "    location1 = item1[COL_LOCATION]\n",
    "    location2 = item2[COL_LOCATION]\n",
    "    \n",
    "    return 1 if location1 == location2 else 0\n",
    "\n",
    "def distance_between_coordinates(item1, item2):\n",
    "    lat1 = float(item1[COL_LAT])\n",
    "    lat2 = float(item2[COL_LAT])\n",
    "    lon1 = float(item1[COL_LON])\n",
    "    lon2 = float(item2[COL_LON])\n",
    "    \n",
    "    point1 = (lon1, lat1)\n",
    "    point2 = (lon2, lat2)\n",
    "    \n",
    "    from geopy.distance import vincenty\n",
    "    return vincenty(point1, point2).miles\n",
    "\n",
    "def same_region(item1, item2):\n",
    "    location1 = item1[COL_LOCATION]\n",
    "    location2 = item2[COL_LOCATION]\n",
    "    \n",
    "    region1 = map_regions[location1]\n",
    "    region2 = map_regions[location2]\n",
    "    \n",
    "    return 1 if region1 == region2 else 0\n",
    "\n",
    "def same_metro(item1, item2):\n",
    "    metro1 = item1[COL_METRO]\n",
    "    metro2 = item2[COL_METRO]\n",
    "    \n",
    "    return 1 if metro1 == metro2 else 0\n",
    "\n",
    "def get_features(item1, item2, label):\n",
    "    fx = []\n",
    "    fx.append(same_category(item1, item2))\n",
    "    fx.append(same_parent_category(item1, item2))\n",
    "    \n",
    "    fx.append(same_price(item1, item2))\n",
    "    fx.append(price_diff_percent(item1, item2))\n",
    "    \n",
    "    fx.append(same_lat(item1, item2))\n",
    "    fx.append(same_lon(item1, item2))\n",
    "    fx.append(same_location(item1, item2))\n",
    "    fx.append(distance_between_coordinates(item1, item2))\n",
    "    \n",
    "    fx.append(same_region(item1, item2))\n",
    "    fx.append(same_metro(item1, item2))\n",
    "    \n",
    "    fx.append(same_title(item1, item2))\n",
    "    fx.append(same_description(item1, item2))\n",
    "    \n",
    "    fx.append(same_images(item1, item2))\n",
    "    fx.append(number_of_same_images(item1, item2))\n",
    "    \n",
    "    return (fx, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 1 µs, total: 20 µs\n",
      "Wall time: 22.9 µs\n",
      "CPU times: user 91 µs, sys: 8 µs, total: 99 µs\n",
      "Wall time: 101 µs\n",
      "CPU times: user 0 ns, sys: 4.01 ms, total: 4.01 ms\n",
      "Wall time: 4.2 ms\n",
      "CPU times: user 3.13 ms, sys: 4 µs, total: 3.14 ms\n",
      "Wall time: 3.32 ms\n",
      "CPU times: user 6.89 ms, sys: 0 ns, total: 6.89 ms\n",
      "Wall time: 7.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  1,\n",
       "  1,\n",
       "  0.0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0.0,\n",
       "  1,\n",
       "  1,\n",
       "  1.0000000000000002,\n",
       "  0.99999999999999989,\n",
       "  False,\n",
       "  0],\n",
       " 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1 = map_items[pairs[0][0]]\n",
    "item2 = map_items[pairs[0][1]]\n",
    "%time price_diff_percent(item1, item2)\n",
    "%time distance_between_coordinates(item1, item2)\n",
    "%time same_title(item1, item2)\n",
    "%time same_description(item1, item2)\n",
    "\n",
    "%time get_features(item1, item2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 0.0, 1, 1, 1, 0.0, 1, 1, 1.0000000000000002, 0.99999999999999989, False, 0], 1)\n"
     ]
    }
   ],
   "source": [
    "def get_train_data():\n",
    "    data = []\n",
    "    for pair in pairs:\n",
    "        item1 = map_items[pair[0]]\n",
    "        item2 = map_items[pair[1]]\n",
    "        label = int(pair[2])\n",
    "\n",
    "        xy = get_features(item1, item2, label)\n",
    "        data.append(xy)\n",
    "        \n",
    "    return data\n",
    "\n",
    "train = get_train_data()\n",
    "print train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "datas = {}\n",
    "def get_train_data_worker(i, n):\n",
    "    data = []\n",
    "    start = len(pairs) / n * i\n",
    "    end = len(pairs) / n * (i+1)\n",
    "    end = min(end, len(pairs))\n",
    "    job = pairs[start:end]\n",
    "    for pair in job:\n",
    "        item1 = map_items[pair[0]]\n",
    "        item2 = map_items[pair[1]]\n",
    "        label = int(pair[2])\n",
    "\n",
    "        xy = get_features(item1, item2, label)\n",
    "        data.append(xy)\n",
    "    datas[i] = data\n",
    "    \n",
    "def get_train_data_async():\n",
    "    parts = 4\n",
    "    \n",
    "    threads = []\n",
    "    for i in range(parts):\n",
    "        thread=Thread(target=get_train_data_worker, args=(i+1, parts))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    data = []\n",
    "    for key in datas:\n",
    "        data = data + datas[key]\n",
    "        \n",
    "    return data\n",
    "\n",
    "train = get_train_data_async()\n",
    "print train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676728676729\n",
      "[ 0.          0.          0.07517363  0.          0.00242139  0.00482038\n",
      "  0.00659635  0.06950367  0.00408102  0.00346837  0.22377067  0.58964515\n",
      "  0.01378844  0.00673094]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data = train_test_split(train, test_size=0.20, train_size=0.80)\n",
    "\n",
    "train_x = [x[0] for x in train_data]\n",
    "train_y = [x[1] for x in train_data]\n",
    "\n",
    "test_x = [x[0] for x in test_data]\n",
    "test_y = [x[1] for x in test_data]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "print classifier.score(test_x, test_y)\n",
    "print classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
