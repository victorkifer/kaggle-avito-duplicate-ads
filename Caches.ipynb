{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_csv(filename, hasHeader=False):\n",
    "    data = []\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        if (hasHeader):\n",
    "            next(reader, None)\n",
    "            \n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_csv(filename, header, data):\n",
    "    with open(filename, 'w+') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"')\n",
    "        if header is not None:\n",
    "            writer.writerow(header)\n",
    "            \n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def file_available(filename):\n",
    "    return os.path.exists(filename)\\\n",
    "        and os.path.isfile(filename)\\\n",
    "        and os.access(\"myfile\", os.R_OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COL_ID=0\n",
    "COL_CATEGORY_ID=1\n",
    "COL_TITLE=2\n",
    "COL_DESCRIPTION=3\n",
    "COL_IMAGES=4\n",
    "COL_JSON=5\n",
    "COL_PRICE=6\n",
    "COL_LOCATION=7\n",
    "COL_METRO=8\n",
    "COL_LAT=9\n",
    "COL_LON=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imagehash\n",
    "\n",
    "# 0 means absolutely equal (int)\n",
    "IMAGE_DIFFERENCE_THRESHOLD = 0\n",
    "\n",
    "def load_image_hashes():\n",
    "    map_hashes = {}\n",
    "    for i in range(10):\n",
    "        data = read_csv('processed_data/hashes' + str(i) + '.csv')\n",
    "        for row in data:\n",
    "            map_hashes[row[0]] = row[1]\n",
    "    return map_hashes\n",
    "\n",
    "def number_of_same_images(image_hashes, item1, item2):\n",
    "    imgs1 = item1[COL_IMAGES].split(',')\n",
    "    imgs2 = item2[COL_IMAGES].split(',')\n",
    "    imgs1 = set(filter(bool, [x.strip() for x in imgs1]))\n",
    "    imgs2 = set(filter(bool, [x.strip() for x in imgs2]))\n",
    "    \n",
    "    count = 0\n",
    "    for img1 in imgs1:\n",
    "        for img2 in imgs2:\n",
    "            try:\n",
    "                if imagehash.hex_to_hash(image_hashes[img1]) -\\\n",
    "                    imagehash.hex_to_hash(image_hashes[img2]) \\\n",
    "                    <= IMAGE_DIFFERENCE_THRESHOLD:\n",
    "                    count += 1\n",
    "                    break\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                \n",
    "    minlen = min(len(imgs1), len(imgs2))\n",
    "    \n",
    "    if minlen == 0:\n",
    "        print ('Some items have 0 images', item1[COL_ID], item2[COL_ID])\n",
    "        return (count, 0)\n",
    "    \n",
    "    return (count, count / minlen)\n",
    "\n",
    "def load_items_map():\n",
    "    items = read_csv('data/ItemInfo_train.csv', hasHeader=True)\n",
    "    print('Train items', len(items))\n",
    "    print('Item example', items[0])\n",
    "    map_items = dict()\n",
    "    for item in items:\n",
    "        map_items[item[COL_ID]] = item\n",
    "    return map_items\n",
    "\n",
    "def load_item_pairs():\n",
    "    pairs = read_csv('data/ItemPairs_train.csv', hasHeader=True)\n",
    "    print('Train pairs', len(pairs))\n",
    "    print('Example pair', pairs[0])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def titles():\n",
    "    map_hashes = {}\n",
    "    data = read_csv('titles_sim.csv')\n",
    "    for row in data:\n",
    "        map_hashes[row[0] + '+' + row[1]] = row[2]\n",
    "    return map_hashes\n",
    "\n",
    "def descriptions():\n",
    "    map_hashes = {}\n",
    "    data = read_csv('descriptions_sim.csv')\n",
    "    for row in data:\n",
    "        map_hashes[row[0] + '+' + row[1]] = row[2]\n",
    "    return map_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_categories():\n",
    "    categories = read_csv('data/Category.csv')\n",
    "    print('Categories', len(categories))\n",
    "    map_parent_category = dict()\n",
    "    for category in categories:\n",
    "        map_parent_category[category[0]] = category[1]\n",
    "    return map_parent_category\n",
    "\n",
    "def get_regions():\n",
    "    locations = read_csv('data/Location.csv', hasHeader=True)\n",
    "    print('Locations', len(locations))\n",
    "    map_regions = dict()\n",
    "    for location in locations:\n",
    "        map_regions[location[0]] = location[1]\n",
    "    return map_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles_map = titles()\n",
    "descriptions_map = descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_hashes = load_image_hashes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories 52\n",
      "Locations 3449\n"
     ]
    }
   ],
   "source": [
    "map_parent_category = get_categories()\n",
    "map_regions = get_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_category(item1, item2):\n",
    "    cat1 = item1[COL_CATEGORY_ID]\n",
    "    cat2 = item2[COL_CATEGORY_ID]\n",
    "    \n",
    "    return 1 if cat1 == cat2 else 0\n",
    "\n",
    "def same_parent_category(item1, item2):\n",
    "    cat1 = item1[COL_CATEGORY_ID]\n",
    "    cat2 = item2[COL_CATEGORY_ID]\n",
    "    \n",
    "    par_cat1 = map_parent_category[cat1]\n",
    "    par_cat2 = map_parent_category[cat2]\n",
    "    \n",
    "    return 1 if par_cat1 == par_cat2 else 0\n",
    "\n",
    "def same_price(item1, item2):\n",
    "    price1 = item1[COL_PRICE]\n",
    "    price2 = item2[COL_PRICE]\n",
    "    \n",
    "    return 1 if price1 == price2 else 0\n",
    "\n",
    "def safe_parse(str):\n",
    "    try:\n",
    "        return float(item1[COL_PRICE].replace(',', ''))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def price_diff_percent(item1, item2):\n",
    "    price1 = safe_parse(item1[COL_PRICE])\n",
    "    price2 = safe_parse(item2[COL_PRICE])\n",
    "    \n",
    "    import math\n",
    "    avg_price = (price1 + price2) / 2.0\n",
    "    \n",
    "    if avg_price != 0:\n",
    "        return math.fabs(price1 - price2) / avg_price\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_lat(item1, item2):\n",
    "    lat1 = item1[COL_LAT]\n",
    "    lat2 = item2[COL_LAT]\n",
    "    \n",
    "    return 1 if lat1 == lat2 else 0\n",
    "\n",
    "def same_lon(item1, item2):\n",
    "    lon1 = item1[COL_LON]\n",
    "    lon2 = item2[COL_LON]\n",
    "    \n",
    "    return 1 if lon1 == lon2 else 0\n",
    "\n",
    "def same_location(item1, item2):\n",
    "    location1 = item1[COL_LOCATION]\n",
    "    location2 = item2[COL_LOCATION]\n",
    "    \n",
    "    return 1 if location1 == location2 else 0\n",
    "\n",
    "def distance_between_coordinates(item1, item2):\n",
    "    lat1 = float(item1[COL_LAT])\n",
    "    lat2 = float(item2[COL_LAT])\n",
    "    lon1 = float(item1[COL_LON])\n",
    "    lon2 = float(item2[COL_LON])\n",
    "    \n",
    "    point1 = (lon1, lat1)\n",
    "    point2 = (lon2, lat2)\n",
    "    \n",
    "    from geopy.distance import vincenty\n",
    "    return vincenty(point1, point2).miles\n",
    "\n",
    "def same_region(item1, item2):\n",
    "    location1 = item1[COL_LOCATION]\n",
    "    location2 = item2[COL_LOCATION]\n",
    "    \n",
    "    region1 = map_regions[location1]\n",
    "    region2 = map_regions[location2]\n",
    "    \n",
    "    return 1 if region1 == region2 else 0\n",
    "\n",
    "def same_metro(item1, item2):\n",
    "    metro1 = item1[COL_METRO]\n",
    "    metro2 = item2[COL_METRO]\n",
    "    \n",
    "    return 1 if metro1 == metro2 else 0\n",
    "\n",
    "def get_features(item1, item2, label):\n",
    "    fx = []\n",
    "    fx.append(same_category(item1, item2))\n",
    "    fx.append(same_parent_category(item1, item2))\n",
    "    \n",
    "    fx.append(same_price(item1, item2))\n",
    "    fx.append(price_diff_percent(item1, item2))\n",
    "    \n",
    "    fx.append(same_lat(item1, item2))\n",
    "    fx.append(same_lon(item1, item2))\n",
    "    fx.append(same_location(item1, item2))\n",
    "    fx.append(distance_between_coordinates(item1, item2))\n",
    "    \n",
    "    fx.append(same_region(item1, item2))\n",
    "    fx.append(same_metro(item1, item2))\n",
    "    \n",
    "    fx.append(titles_map[item1[COL_ID] + '+' + item2[COL_ID]])\n",
    "    fx.append(descriptions_map[item1[COL_ID] + '+' + item2[COL_ID]])\n",
    "    \n",
    "    fx.append(same_images(item1, item2))\n",
    "    fx.append(number_of_same_images(item1, item2))\n",
    "    \n",
    "    return (fx, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_map = load_items_map()\n",
    "pairs = load_item_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1+4112648'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fa464e04466a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-fa464e04466a>\u001b[0m in \u001b[0;36mget_train_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-4aa2380d940b>\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(item1, item2, label)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mfx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCOL_ID\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'+'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mitem2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCOL_ID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mfx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptions_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCOL_ID\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'+'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mitem2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCOL_ID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mfx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1+4112648'"
     ]
    }
   ],
   "source": [
    "def get_train_data():   \n",
    "    data = []\n",
    "    for pair in pairs:\n",
    "        item1 = items_map[pair[0]]\n",
    "        item2 = items_map[pair[1]]\n",
    "        label = int(pair[2])\n",
    "\n",
    "        xy = get_features(item1, item2, label)\n",
    "        data.append(xy)\n",
    "        \n",
    "    return data\n",
    "\n",
    "train = get_train_data()\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Free up memory\n",
    "items_map = None\n",
    "pairs = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
